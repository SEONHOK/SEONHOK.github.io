---
title: "Max-affine regression"
collection: talks
type: "Talk"
permalink: /talks/2012-03-01-talk-1
venue: "UC San Francisco, Department of Testing"
date: 2012-03-01
location: "San Francisco, California"
---

The max-affine regression model is relevant in fields like economics, statistics, and machine learning, but its NP-hard and non-convex nature makes regression challenging. Our research demonstrates that both Gradient Descent (GD) and Stochastic Gradient Descent (SGD) can effectively learn this model. We provide theoretical insights on the data requirements, iteration counts, and error bounds associated with these first-order methods. Furthermore, we found that for large-scale problems, SGD is more data-efficient and converges up to twice as fast and with five times less error than the baseline alternating minimization algorithm.